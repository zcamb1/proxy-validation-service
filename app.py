from flask import Flask, jsonify, request
import requests
import threading
import time
import json
import os
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import random

app = Flask(__name__)

# Cache proxy s·ªëng
proxy_cache = {
    "http": [],
    "last_update": None,
    "total_checked": 0,
    "alive_count": 0
}

# Ngu·ªìn proxy ƒë∆∞·ª£c ph√¢n lo·∫°i theo y√™u c·∫ßu user
PROXY_SOURCE_LINKS = {
    # Ngu·ªìn c√≥ protocol r√µ r√†ng - ki·ªÉm tra theo ƒë√∫ng protocol
    "Server Alpha": {
        "http": "https://cdn.jsdelivr.net/gh/databay-labs/free-proxy-list/http.txt",
        "https": "https://cdn.jsdelivr.net/gh/databay-labs/free-proxy-list/https.txt", 
        "socks5": "https://cdn.jsdelivr.net/gh/databay-labs/free-proxy-list/socks5.txt",
    },
    "Network Beta": {
        "http": "https://raw.githubusercontent.com/casa-ls/proxy-list/main/http",
        "socks4": "https://raw.githubusercontent.com/casa-ls/proxy-list/main/socks4",
        "socks5": "https://raw.githubusercontent.com/casa-ls/proxy-list/main/socks5",
        "http_yemixzy": "https://raw.githubusercontent.com/yemixzy/proxy-list/main/proxies/http.txt",
        "socks4_yemixzy": "https://raw.githubusercontent.com/yemixzy/proxy-list/main/proxies/socks4.txt",
        "socks5_yemixzy": "https://raw.githubusercontent.com/yemixzy/proxy-list/main/proxies/socks5.txt",
    },
    "Gateway Pro": {
        "http": "https://api.proxyscrape.com/v2/?request=getproxies&protocol=http",
        "socks4": "https://api.proxyscrape.com/v2/?request=getproxies&protocol=socks4", 
        "socks5": "https://api.proxyscrape.com/v2/?request=getproxies&protocol=socks5",
        "https": "https://api.proxyscrape.com/v2/?request=getproxies&protocol=https",
    },
    
    # Mixed sources - th·ª≠ t·∫•t c·∫£ protocol, c√°i n√†o live th√¨ th√™m v√†o (ki·ªÉm tra sau)
    "Mixed Sources": {
        "mixed_hendrikbgr": "https://raw.githubusercontent.com/hendrikbgr/Free-Proxy-Repo/master/proxy_list.txt",
        "mixed_mrmarble": "https://raw.githubusercontent.com/MrMarble/proxy-list/main/all.txt",
    }
}

def parse_proxy_line(proxy_string, default_type="auto"):
    """Parse proxy line gi·ªëng y h·ªát tool - auto detect protocol"""
    try:
        add_log(f"üîç Parsing proxy: {proxy_string}", "info")
        
        # Tr∆∞·ªùng h·ª£p username:password@host:port
        if '@' in proxy_string:
            auth, hostport = proxy_string.split('@', 1)
            if ':' in auth:
                username, password = auth.split(':', 1)
            else:
                username, password = auth, ""
            
            if ':' in hostport:
                host, port = hostport.split(':', 1)
            else:
                add_log(f"‚ùå Invalid format: no port in {hostport}", "error")
                return None
        # Tr∆∞·ªùng h·ª£p host:port
        elif ':' in proxy_string:
            username, password = "", ""
            host, port = proxy_string.split(':', 1)
        else:
            add_log(f"‚ùå Invalid format: no colon in {proxy_string}", "error")
            return None
        
        # Auto-detect protocol d·ª±a tr√™n port (gi·ªëng tool)
        if default_type == "auto":
            port_num = int(port)
            if port_num in [80, 8080, 3128]:
                proxy_type = "http"
            elif port_num in [443, 8443]:
                proxy_type = "https"
            elif port_num in [1080, 1081]:
                proxy_type = "socks5"
            elif port_num in [1090, 4145]:
                proxy_type = "socks4"
            else:
                proxy_type = "http"  # Default HTTP
        else:
            proxy_type = default_type
        
        add_log(f"‚úÖ Parsed: {host}:{port} as {proxy_type} protocol", "success")
        
        return {
            'host': host,
            'port': port,
            'username': username,
            'password': password,
            'type': proxy_type,
            'proxy_str': f"{username}:{'*'*len(password)}@{host}:{port}" if username else f"{host}:{port}"
        }
        
    except Exception as e:
        add_log(f"‚ùå Parse error for '{proxy_string}': {str(e)}", "error")
        return None

def check_single_proxy(proxy_string, timeout=8):
    """Ki·ªÉm tra 1 proxy - gi·ªëng y h·ªát logic tool"""
    add_log(f"üß™ Checking proxy: {proxy_string}", "info")
    
    # Parse proxy gi·ªëng tool
    parsed = parse_proxy_line(proxy_string, "auto")
    if not parsed:
        add_log(f"‚ùå Failed to parse: {proxy_string}", "error")
        return None
    
    host = parsed['host']
    port = parsed['port']
    proxy_type = parsed['type']
    username = parsed['username']
    password = parsed['password']
    
    add_log(f"üîß Testing {host}:{port} as {proxy_type} protocol", "info")
    
    result = {
        'host': host,
        'port': int(port),
        'type': proxy_type,
        'username': username,
        'password': password,
        'proxy_str': parsed['proxy_str'],
        'live': False,
        'latency': 0,
        'ip': None,
        'error': None,
        'speed': 0,
        'status': 'dead',
        'checked_at': datetime.now().isoformat(),
        'proxy_string': f"{host}:{port}",
        'full_proxy': proxy_string,
        'has_auth': bool(username and password)
    }
    
    # Setup proxy URL gi·ªëng tool
    if username:
        proxy_url = f"{proxy_type}://{username}:{password}@{host}:{port}"
    else:
        proxy_url = f"{proxy_type}://{host}:{port}"
        
    proxies = {
        "http": proxy_url,
        "https": proxy_url
    }
    
    # Test URLs gi·ªëng tool (ipify ch√≠nh x√°c nh∆∞ tool)
    test_urls = [
        "https://api.ipify.org?format=text",  # Primary - gi·ªëng tool
        "https://api.elevenlabs.io/v1/models",  # ElevenLabs test
        "https://httpbin.org/ip"  # Fallback
    ]
    
    try:
        start_time = time.time()
        
        for i, test_url in enumerate(test_urls):
            try:
                add_log(f"üåê Testing {host}:{port} v·ªõi {test_url}", "info")
                
                response = requests.get(
                    test_url,
                    proxies=proxies,
                    timeout=timeout,
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                )
                
                end_time = time.time()
                latency = round((end_time - start_time) * 1000)  # milliseconds
                speed = round(end_time - start_time, 2)  # seconds
                
                # Handle response gi·ªëng tool
                if "api.ipify.org" in test_url:
                    if response.status_code == 200:
                        ip = response.text.strip()
                        add_log(f"‚úÖ IPIFY SUCCESS: {host}:{port} ‚Üí IP: {ip} | Latency: {latency}ms", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': ip,
                            'status': 'alive',
                            'error': None
                        })
                        return result
                    else:
                        add_log(f"‚ùå IPIFY failed: HTTP {response.status_code}", "error")
                        
                elif "api.elevenlabs.io" in test_url:
                    # ElevenLabs ch·∫•p nh·∫≠n 401, 403, 404, 200
                    if response.status_code in [401, 403, 404, 200]:
                        add_log(f"‚úÖ ELEVENLABS SUCCESS: {host}:{port} ‚Üí HTTP {response.status_code} | Latency: {latency}ms", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': f"ElevenLabs HTTP {response.status_code}",
                            'status': 'alive',
                            'error': None
                        })
                        return result
                    else:
                        add_log(f"‚ùå ElevenLabs failed: HTTP {response.status_code}", "error")
                        
                else:  # httpbin
                    if response.status_code == 200:
                        try:
                            ip_data = response.json()
                            ip = ip_data.get('origin', 'Unknown')
                            if ',' in ip:
                                ip = ip.split(',')[0]
                        except:
                            ip = "HttpBin Response"
                        
                        add_log(f"‚úÖ HTTPBIN SUCCESS: {host}:{port} ‚Üí IP: {ip} | Latency: {latency}ms", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': ip,
                            'status': 'alive',
                            'error': None
                        })
                        return result
                    else:
                        add_log(f"‚ùå HttpBin failed: HTTP {response.status_code}", "error")
                        
            except requests.exceptions.ProxyError as e:
                add_log(f"‚ùå Proxy error with {test_url}: {str(e)}", "error")
                result['error'] = f"Proxy error: {e}"
            except requests.exceptions.ConnectTimeout:
                add_log(f"‚ùå Connect timeout with {test_url}", "error")
                result['error'] = "Connect timeout"
            except requests.exceptions.ReadTimeout:
                add_log(f"‚ùå Read timeout with {test_url}", "error")
                result['error'] = "Read timeout"
            except requests.exceptions.ConnectionError as e:
                add_log(f"‚ùå Connection error with {test_url}: {str(e)}", "error")
                result['error'] = f"Connection error: {e}"
            except Exception as e:
                add_log(f"‚ùå Unknown error with {test_url}: {str(e)}", "error")
                result['error'] = f"Error: {e}"
                
        # N·∫øu t·∫•t c·∫£ test URLs ƒë·ªÅu fail
        add_log(f"üíÄ PROXY DEAD: {host}:{port} - All tests failed", "error")
        return result
        
    except Exception as e:
        add_log(f"‚ùå Critical error checking {host}:{port}: {str(e)}", "error")
        result['error'] = f"Critical error: {e}"
        return result

def check_mixed_proxy_all_protocols(proxy_string, timeout=8):
    """
    Ki·ªÉm tra mixed proxy v·ªõi t·∫•t c·∫£ protocol (http, https, socks4, socks5)
    Tr·∫£ v·ªÅ k·∫øt qu·∫£ cho protocol ƒë·∫ßu ti√™n th√†nh c√¥ng
    """
    protocols_to_try = ['http', 'https', 'socks4', 'socks5']
    
    # Parse proxy
    parsed = parse_proxy_line(proxy_string, "auto")
    if not parsed:
        add_log(f"‚ùå Mixed proxy parse failed: {proxy_string}", "error")
        return None
    
    host = parsed['host']
    port = parsed['port']
    username = parsed.get('username', '')
    password = parsed.get('password', '')
    
    for protocol in protocols_to_try:
        try:
            add_log(f"üß™ Testing mixed proxy {host}:{port} v·ªõi protocol {protocol}", "info")
            
            result = {
                'host': host,
                'port': int(port),
                'type': protocol,
                'username': username,
                'password': password,
                'proxy_str': parsed['proxy_str'],
                'live': False,
                'latency': 0,
                'ip': None,
                'error': None,
                'speed': 0,
                'status': 'dead',
                'checked_at': datetime.now().isoformat(),
                'proxy_string': f"{host}:{port}",
                'full_proxy': proxy_string,
                'has_auth': bool(username and password)
            }
            
            # Setup proxy URL
            if username:
                proxy_url = f"{protocol}://{username}:{password}@{host}:{port}"
            else:
                proxy_url = f"{protocol}://{host}:{port}"
                
            proxies = {
                "http": proxy_url,
                "https": proxy_url
            }
            
            # Test URLs
            test_urls = [
                "https://api.ipify.org?format=text",
                "https://api.elevenlabs.io/v1/models",
                "https://httpbin.org/ip"
            ]
            
            start_time = time.time()
            
            for test_url in test_urls:
                try:
                    response = requests.get(
                        test_url,
                        proxies=proxies,
                        timeout=timeout,
                        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                    )
                    
                    end_time = time.time()
                    latency = round((end_time - start_time) * 1000)
                    speed = round(end_time - start_time, 2)
                    
                    # Check response based on test URL
                    if "api.ipify.org" in test_url and response.status_code == 200:
                        ip = response.text.strip()
                        add_log(f"‚úÖ Mixed proxy {host}:{port} LIVE v·ªõi {protocol} ‚Üí IP: {ip}", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': ip,
                            'status': 'alive',
                            'type': protocol,  # Update to working protocol
                            'error': None
                        })
                        return result
                        
                    elif "api.elevenlabs.io" in test_url and response.status_code in [401, 403, 404, 200]:
                        add_log(f"‚úÖ Mixed proxy {host}:{port} LIVE v·ªõi {protocol} ‚Üí ElevenLabs OK", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': f"ElevenLabs HTTP {response.status_code}",
                            'status': 'alive',
                            'type': protocol,
                            'error': None
                        })
                        return result
                        
                    elif "httpbin.org" in test_url and response.status_code == 200:
                        try:
                            ip_data = response.json()
                            ip = ip_data.get('origin', 'Unknown')
                            if ',' in ip:
                                ip = ip.split(',')[0]
                        except:
                            ip = "HttpBin Response"
                        
                        add_log(f"‚úÖ Mixed proxy {host}:{port} LIVE v·ªõi {protocol} ‚Üí HttpBin OK", "success")
                        result.update({
                            'live': True,
                            'latency': latency,
                            'speed': speed,
                            'ip': ip,
                            'status': 'alive',
                            'type': protocol,
                            'error': None
                        })
                        return result
                
                except requests.exceptions.RequestException:
                    continue  # Try next URL
                    
        except Exception as e:
            add_log(f"‚ùå Mixed proxy {host}:{port} failed v·ªõi {protocol}: {e}", "error")
            continue  # Try next protocol
    
    add_log(f"üíÄ Mixed proxy {host}:{port} DEAD v·ªõi t·∫•t c·∫£ protocol", "error")
    return None

def add_log(message, log_type="info"):
    """Add log entry"""
    service_status["logs"] = service_status.get("logs", [])
    service_status["logs"].append({
        "timestamp": datetime.now().isoformat(),
        "message": message,
        "type": log_type
    })
    # Keep only last 100 logs
    if len(service_status["logs"]) > 100:
        service_status["logs"] = service_status["logs"][-100:]
    print(f"[{log_type.upper()}] {message}")

def fetch_proxies_from_sources():
    """L·∫•y proxy t·ª´ c√°c ngu·ªìn v·ªõi logic th√¥ng minh: categorized tr∆∞·ªõc, mixed sau"""
    service_status["is_fetching"] = True
    service_status["sources_checked"] = 0
    service_status["current_progress"] = 0
    
    all_proxies = []
    categorized_proxies = []
    mixed_proxies = []
    
    add_log("üîç B·∫Øt ƒë·∫ßu fetch proxy t·ª´ c√°c ngu·ªìn - CATEGORIZED tr∆∞·ªõc, MIXED sau...", "info")
    
    # Step 1: Process categorized sources first (Server Alpha, Network Beta, Gateway Pro)
    categorized_sources = {k: v for k, v in PROXY_SOURCE_LINKS.items() if k != "Mixed Sources"}
    
    for i, (source_name, source_urls) in enumerate(categorized_sources.items()):
        try:
            add_log(f"üì• [CATEGORIZED] ƒêang fetch t·ª´ {source_name}...", "info")
            
            for protocol, source_url in source_urls.items():
                try:
                    add_log(f"üîó Fetching {source_name} - {protocol}: {source_url[:50]}...", "info")
                    response = requests.get(source_url, timeout=30)
                    
                    if response.status_code == 200:
                        content = response.text
                        lines = content.strip().split('\n')
                        source_proxies = []
                        
                        for line in lines:
                            line = line.strip()
                            if not line or line.startswith('#'):
                                continue
                                
                            if ':' in line:
                                proxy_candidate = line.strip()
                                
                                # Remove common prefixes
                                for prefix in ['http://', 'https://', 'socks4://', 'socks5://']:
                                    if proxy_candidate.startswith(prefix):
                                        proxy_candidate = proxy_candidate[len(prefix):]
                                
                                # For categorized sources, force the protocol from URL
                                parsed = parse_proxy_line(proxy_candidate, protocol.split('_')[0])  # Remove suffix like _yemixzy
                                if parsed:
                                    clean_proxy = f"{parsed['host']}:{parsed['port']}"
                                    source_proxies.append(clean_proxy)
                        
                        categorized_proxies.extend(source_proxies)
                        add_log(f"‚úÖ {source_name} ({protocol}): T√¨m th·∫•y {len(source_proxies)} proxy", "success")
                    else:
                        add_log(f"‚ùå {source_name} ({protocol}): HTTP {response.status_code}", "error")
                
                except Exception as e:
                    add_log(f"‚ùå {source_name} ({protocol}): {str(e)}", "error")
            
        except Exception as e:
            add_log(f"‚ùå {source_name}: {str(e)}", "error")
            
        service_status["sources_checked"] = i + 1
        service_status["current_progress"] = i + 1
    
    add_log(f"üéØ CATEGORIZED ho√†n th√†nh: {len(categorized_proxies)} proxy", "success")
    
    # Step 2: Process mixed sources (will be checked with all protocols later)
    if "Mixed Sources" in PROXY_SOURCE_LINKS:
        mixed_source_urls = PROXY_SOURCE_LINKS["Mixed Sources"]
        
        for protocol, source_url in mixed_source_urls.items():
            try:
                add_log(f"üì• [MIXED] ƒêang fetch t·ª´ {protocol}: {source_url[:50]}...", "info")
                response = requests.get(source_url, timeout=30)
                
                if response.status_code == 200:
                    content = response.text
                    lines = content.strip().split('\n')
                    source_proxies = []
                    
                    for line in lines:
                        line = line.strip()
                        if not line or line.startswith('#'):
                            continue
                            
                        if ':' in line:
                            proxy_candidate = line.strip()
                            
                            # Remove common prefixes
                            for prefix in ['http://', 'https://', 'socks4://', 'socks5://']:
                                if proxy_candidate.startswith(prefix):
                                    proxy_candidate = proxy_candidate[len(prefix):]
                            
                            # For mixed, use auto detection
                            parsed = parse_proxy_line(proxy_candidate, "auto")
                            if parsed:
                                clean_proxy = f"{parsed['host']}:{parsed['port']}"
                                source_proxies.append(clean_proxy)
                    
                    mixed_proxies.extend(source_proxies)
                    add_log(f"‚úÖ MIXED {protocol}: T√¨m th·∫•y {len(source_proxies)} proxy", "success")
                else:
                    add_log(f"‚ùå MIXED {protocol}: HTTP {response.status_code}", "error")
            
            except Exception as e:
                add_log(f"‚ùå MIXED {protocol}: {str(e)}", "error")
    
    add_log(f"üéØ MIXED ho√†n th√†nh: {len(mixed_proxies)} proxy", "success")
    
    # Combine: categorized first, then mixed
    all_proxies = categorized_proxies + mixed_proxies
    
    # Remove duplicates
    unique_proxies = list(set(all_proxies))
    add_log(f"üéâ T·ªïng c·ªông thu th·∫≠p {len(unique_proxies)} proxy unique (Categorized: {len(categorized_proxies)}, Mixed: {len(mixed_proxies)})", "success")
    
    service_status["is_fetching"] = False
    return unique_proxies

def validate_proxy_batch_fast(proxy_list, max_workers=40, target_alive=50, chunk_size=80, timeout=8):
    """Validate proxy list NHANH v·ªõi early stopping v√† real-time updates"""
    service_status["is_validating"] = True
    service_status["total_to_check"] = len(proxy_list)
    service_status["current_progress"] = 0
    
    alive_proxies = []
    dead_count = 0
    total_completed = 0
    
    add_log(f"‚ö° B·∫ÆT ƒê·∫¶U VALIDATION NHANH: {len(proxy_list)} proxy v·ªõi {max_workers} workers | Target: {target_alive} alive", "info")
    
    # Chia proxy th√†nh chunks nh·ªè ƒë·ªÉ c√≥ k·∫øt qu·∫£ s·ªõm
    for chunk_start in range(0, len(proxy_list), chunk_size):
        chunk_end = min(chunk_start + chunk_size, len(proxy_list))
        chunk = proxy_list[chunk_start:chunk_end]
        
        add_log(f"üöÄ Chunk {chunk_start//chunk_size + 1}: Testing {len(chunk)} proxies...", "info")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit chunk v·ªõi timeout nhanh
            future_to_proxy = {
                executor.submit(check_single_proxy, proxy, timeout): proxy 
                for proxy in chunk
            }
            
            chunk_completed = 0
            for future in as_completed(future_to_proxy):
                try:
                    result = future.result(timeout=1)  # Quick result retrieval
                    chunk_completed += 1
                    total_completed += 1
                    service_status["current_progress"] = total_completed
                    
                    if result and result.get('status') == 'alive':
                        alive_proxies.append(result)
                        add_log(f"‚úÖ ALIVE #{len(alive_proxies)}: {result['proxy_string']} ‚Üí {result.get('ip', 'N/A')} | {result.get('latency', 0)}ms", "success")
                        
                        # EARLY STOPPING - ƒê·ªß proxy s·ªëng r·ªìi!
                        if len(alive_proxies) >= target_alive:
                            add_log(f"üéØ ƒê·∫†T TARGET: {len(alive_proxies)}/{target_alive} proxy s·ªëng! D·ª™NG VALIDATION S·ªöM.", "success")
                            service_status["is_validating"] = False
                            
                            # Update final cache ngay l·∫≠p t·ª©c
                            proxy_cache["http"] = alive_proxies
                            proxy_cache["last_update"] = datetime.now().isoformat()
                            proxy_cache["total_checked"] = total_completed
                            proxy_cache["alive_count"] = len(alive_proxies)
                            
                            return alive_proxies
                    else:
                        dead_count += 1
                    
                    # Real-time progress update m·ªói 10 proxy
                    if chunk_completed % 10 == 0:
                        progress_percent = round((total_completed / len(proxy_list)) * 100, 1)
                        success_rate = round((len(alive_proxies) / total_completed) * 100, 1) if total_completed > 0 else 0
                        add_log(f"üìä Progress: {total_completed}/{len(proxy_list)} ({progress_percent}%) | ‚úÖ{len(alive_proxies)} ALIVE | üíÄ{dead_count} dead | Rate: {success_rate}%", "info")
                        
                        # Update cache real-time cho UI
                        proxy_cache["http"] = alive_proxies
                        proxy_cache["last_update"] = datetime.now().isoformat()
                        proxy_cache["total_checked"] = total_completed
                        proxy_cache["alive_count"] = len(alive_proxies)
                
                except Exception as e:
                    total_completed += 1
                    dead_count += 1
                    add_log(f"‚ùå Validation error: {str(e)}", "error")
        
        # Sau m·ªói chunk, check n·∫øu ƒë√£ c√≥ ƒë·ªß proxy s·ªëng
        if len(alive_proxies) >= target_alive:
            break
            
        add_log(f"‚úÖ Chunk ho√†n th√†nh: {len(alive_proxies)} alive t·ª´ {total_completed} tested", "info")
    
    service_status["is_validating"] = False
    service_status["current_progress"] = 0
    service_status["total_to_check"] = 0
    
    # Final update
    proxy_cache["http"] = alive_proxies
    proxy_cache["last_update"] = datetime.now().isoformat()
    proxy_cache["total_checked"] = total_completed
    proxy_cache["alive_count"] = len(alive_proxies)
    
    success_rate = round((len(alive_proxies) / total_completed) * 100, 1) if total_completed > 0 else 0
    add_log(f"üéâ VALIDATION HO√ÄN TH√ÄNH: {len(alive_proxies)} proxy s·ªëng / {total_completed} tested | Success rate: {success_rate}%", "success")
    return alive_proxies

def validate_proxy_batch(proxy_list, max_workers=30):
    """Legacy function - redirect to fast version"""
    return validate_proxy_batch_fast(proxy_list, max_workers, target_alive=50)

def background_proxy_refresh():
    """Background task H·ª¢P L√ù - refresh proxy m·ªói 8 ph√∫t v·ªõi c√¢n b·∫±ng t·ªëc ƒë·ªô/ch√≠nh x√°c"""
    while True:
        try:
            add_log("üîÑ B·∫ÆT ƒê·∫¶U CHU K·ª≤ REFRESH H·ª¢P L√ù (8 ph√∫t)...", "info")
            
            # Fetch new proxies from sources
            raw_proxies = fetch_proxies_from_sources()
            
            if raw_proxies:
                # STRATEGY: C√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c
                limited_proxies = raw_proxies[:600]  # Pool h·ª£p l√Ω 600 proxy
                add_log(f"üéØ Pool: {len(limited_proxies)} proxy t·ª´ {len(raw_proxies)} t·ªïng | Target: 80 alive", "info")
                
                # Use validation c√¢n b·∫±ng v·ªõi timeout 8s
                alive_proxies = validate_proxy_batch_fast(
                    limited_proxies, 
                    max_workers=35,      # Workers h·ª£p l√Ω 
                    target_alive=80,     # Target 80 proxy s·ªëng
                    chunk_size=60,       # Chunks v·ª´a ph·∫£i
                    timeout=8           # Timeout chu·∫©n 8s
                )
                
                # Update cache ngay l·∫≠p t·ª©c
                proxy_cache["http"] = alive_proxies
                proxy_cache["last_update"] = datetime.now().isoformat()
                proxy_cache["total_checked"] = proxy_cache.get("total_checked", 0) + len(limited_proxies)
                proxy_cache["alive_count"] = len(alive_proxies)
                
                success_rate = round((len(alive_proxies) / len(limited_proxies)) * 100, 1)
                add_log(f"‚úÖ CACHE UPDATED: {len(alive_proxies)} proxy s·ªëng | Success rate: {success_rate}%", "success")
                
                # N·∫øu c√≥ ƒë·ªß proxy s·ªëng th√¨ ngh·ªâ chu·∫©n 8 ph√∫t
                if len(alive_proxies) >= 40:
                    sleep_time = 8 * 60  # 8 ph√∫t chu·∫©n
                    add_log(f"üò¥ ƒê·ªß proxy s·ªëng ({len(alive_proxies)}), ngh·ªâ {sleep_time//60} ph√∫t...", "info")
                else:
                    sleep_time = 4 * 60  # 4 ph√∫t n·∫øu √≠t proxy
                    add_log(f"‚ö†Ô∏è √çt proxy s·ªëng ({len(alive_proxies)}), refresh l·∫°i sau {sleep_time//60} ph√∫t...", "info")
                    
            else:
                add_log("‚ùå Kh√¥ng fetch ƒë∆∞·ª£c proxy t·ª´ c√°c ngu·ªìn", "error")
                sleep_time = 5 * 60  # 5 ph√∫t n·∫øu l·ªói
            
            time.sleep(sleep_time)
            
        except Exception as e:
            add_log(f"‚ùå L·ªói trong background refresh: {str(e)}", "error")
            # Sleep 1 minute on error then retry
            time.sleep(60)

# Service status tracking
service_status = {
    "is_fetching": False,
    "is_validating": False,
    "current_progress": 0,
    "total_to_check": 0,
    "sources_checked": 0,
    "total_sources": len(PROXY_SOURCE_LINKS),
    "last_log": "",
    "errors": []
}

# API Routes
@app.route('/')
def home():
    """Homepage v·ªõi th√¥ng tin service"""
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>üöÄ Proxy Validation Service</title>
        <meta charset="UTF-8">
        <meta http-equiv="refresh" content="10">
        <style>
            body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
            .container {{ max-width: 1000px; margin: 0 auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }}
            .header {{ text-align: center; margin-bottom: 30px; }}
            .stats {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 15px; margin: 20px 0; }}
            .live-count {{ font-size: 36px; font-weight: bold; text-align: center; margin-bottom: 15px; }}
            .status-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 15px 0; }}
            .status-item {{ background: rgba(255,255,255,0.1); padding: 15px; border-radius: 10px; }}
            .status-item h4 {{ margin: 0 0 10px 0; font-size: 14px; opacity: 0.8; }}
            .status-item .value {{ font-size: 20px; font-weight: bold; }}
            .progress-container {{ margin: 20px 0; }}
            .progress-bar {{ width: 100%; height: 25px; background: rgba(255,255,255,0.2); border-radius: 12px; overflow: hidden; }}
            .progress-fill {{ height: 100%; background: linear-gradient(90deg, #00c851, #007e33); transition: width 0.3s ease; border-radius: 12px; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold; }}
            .endpoint {{ background: #f8f9fa; padding: 20px; margin: 15px 0; border-radius: 10px; border-left: 5px solid #007bff; }}
            .method {{ color: #fff; padding: 8px 12px; border-radius: 6px; font-size: 12px; font-weight: bold; }}
            .get {{ background: #28a745; }}
            .logs {{ background: #2c3e50; color: #ecf0f1; padding: 20px; border-radius: 10px; margin: 20px 0; height: 200px; overflow-y: auto; font-family: 'Courier New', monospace; font-size: 12px; }}
            .log-item {{ margin: 5px 0; padding: 5px; border-radius: 3px; }}
            .log-info {{ background: rgba(52, 152, 219, 0.1); }}
            .log-success {{ background: rgba(39, 174, 96, 0.1); }}
            .log-error {{ background: rgba(231, 76, 60, 0.1); }}
            .controls {{ text-align: center; margin: 20px 0; }}
            .btn {{ background: #007bff; color: white; padding: 12px 24px; border: none; border-radius: 8px; cursor: pointer; font-size: 16px; margin: 0 10px; transition: all 0.3s; }}
            .btn:hover {{ background: #0056b3; transform: translateY(-2px); }}
            .btn-success {{ background: #28a745; }}
            .btn-success:hover {{ background: #1e7e34; }}
            .sources-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 10px; }}
            .source-item {{ padding: 10px; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #007bff; }}
            .status-indicator {{ display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 8px; }}
            .status-active {{ background: #28a745; animation: pulse 2s infinite; }}
            .status-idle {{ background: #6c757d; }}
            .status-error {{ background: #dc3545; }}
            @keyframes pulse {{ 0% {{ opacity: 1; }} 50% {{ opacity: 0.5; }} 100% {{ opacity: 1; }} }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>üöÄ Proxy Validation Service</h1>
                <p>Service t·ª± ƒë·ªông ki·ªÉm tra proxy s·ªëng m·ªói 5 ph√∫t t·ª´ {len(PROXY_SOURCE_LINKS)} ngu·ªìn kh√°c nhau</p>
            </div>
            
            <div class="stats">
                <div class="live-count" id="proxy-count">0 proxy s·ªëng</div>
                
                <div class="status-grid">
                    <div class="status-item">
                        <h4>üìä T·ªïng ki·ªÉm tra</h4>
                        <div class="value" id="total-checked">0</div>
                    </div>
                    <div class="status-item">
                        <h4>üîÑ Tr·∫°ng th√°i</h4>
                        <div class="value" id="service-status">
                            <span class="status-indicator status-idle"></span>Ch·ªù...
                        </div>
                    </div>
                    <div class="status-item">
                        <h4>‚è∞ L·∫ßn check cu·ªëi</h4>
                        <div class="value" id="last-update">Ch∆∞a check</div>
                    </div>
                    <div class="status-item">
                        <h4>üìà Tu·ªïi cache</h4>
                        <div class="value" id="cache-age">0 ph√∫t</div>
                    </div>
                </div>
                
                <div class="progress-container" id="progress-container" style="display: none;">
                    <div class="progress-bar">
                        <div class="progress-fill" id="progress-fill" style="width: 0%">0%</div>
                    </div>
                </div>
            </div>
            
            <div class="controls">
                <button class="btn btn-success" onclick="forceRefresh()">üîÑ Force Refresh</button>
                <button class="btn" onclick="testAPI()">üß™ Test API</button>
                <button class="btn" onclick="toggleLogs()">üìã Show/Hide Logs</button>
                <button class="btn" onclick="debugStatus()" style="background: #ff6b6b;">üîç Debug Status</button>
                <button class="btn" onclick="testFetch()" style="background: #4ecdc4;">üì• Test Fetch</button>
                <button class="btn" onclick="testValidation()" style="background: #ffe66d;">‚ö° Test Validation</button>
                <button class="btn" onclick="quickCheck()" style="background: #ff9ff3;">üöÄ Quick Check</button>
            </div>
            
            <div class="logs" id="logs-container" style="display: none;">
                <div id="logs">ƒêang t·∫£i logs...</div>
            </div>
            
            <h2>üì° API Endpoints:</h2>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/proxy/alive</strong>
                <p>L·∫•y danh s√°ch proxy s·ªëng</p>
                <p>Params: <code>count</code> (s·ªë l∆∞·ª£ng, default: 50)</p>
                <p>Example: <code>/api/proxy/alive?count=100</code></p>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/proxy/stats</strong>
                <p>Th·ªëng k√™ proxy hi·ªán c√≥</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/proxy/force-refresh</strong>
                <p>Bu·ªôc refresh proxy ngay l·∫≠p t·ª©c</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span>
                <strong>/api/proxy/debug</strong>
                <p>Debug - xem to√†n b·ªô service status v√† cache</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">POST</span>
                <strong>/api/proxy/test-fetch</strong>
                <p>Test fetch proxy t·ª´ 1 source ƒë·ªÉ debug</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">POST</span>
                <strong>/api/proxy/test-single</strong>
                <p>Test validation logic v·ªõi proxy m·∫´u</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">POST</span>
                <strong>/api/proxy/quick-check</strong>
                <p>Quick check - parse 20 proxy v√† validate 5 ƒë·ªÉ test to√†n b·ªô flow</p>
            </div>
            
            <h3>üîó Proxy Sources:</h3>
            <div class="sources-grid">
                {chr(10).join([f'<div class="source-item"><strong>{name}</strong></div>' for name in PROXY_SOURCE_LINKS.keys()])}
            </div>
        </div>
        
        <script>
            let logsVisible = false;
            
            function updateStats() {{
                fetch('/api/proxy/stats')
                    .then(r => r.json())
                    .then(data => {{
                        // Update main stats
                        document.getElementById('proxy-count').textContent = data.alive_count + ' proxy s·ªëng';
                        document.getElementById('total-checked').textContent = data.total_checked || 0;
                        document.getElementById('last-update').textContent = data.last_update ? 
                            new Date(data.last_update).toLocaleString() : 'Ch∆∞a check';
                        document.getElementById('cache-age').textContent = (data.cache_age_minutes || 0) + ' ph√∫t';
                        
                        // Update status indicator
                        const statusEl = document.getElementById('service-status');
                        if (data.is_fetching) {{
                            statusEl.innerHTML = '<span class="status-indicator status-active"></span>ƒêang fetch...';
                        }} else if (data.is_validating) {{
                            statusEl.innerHTML = '<span class="status-indicator status-active"></span>ƒêang validate...';
                        }} else {{
                            statusEl.innerHTML = '<span class="status-indicator status-idle"></span>Ch·ªù cycle k·∫ø';
                        }}
                        
                        // Update progress bar
                        if (data.total_to_check > 0 && (data.is_fetching || data.is_validating)) {{
                            const progress = Math.round((data.current_progress / data.total_to_check) * 100);
                            document.getElementById('progress-container').style.display = 'block';
                            document.getElementById('progress-fill').style.width = progress + '%';
                            document.getElementById('progress-fill').textContent = progress + '%';
                        }} else {{
                            document.getElementById('progress-container').style.display = 'none';
                        }}
                    }})
                    .catch(e => {{
                        console.error('Error updating stats:', e);
                    }});
            }}
            
            function forceRefresh() {{
                document.getElementById('service-status').innerHTML = 
                    '<span class="status-indicator status-active"></span>ƒêang force refresh...';
                fetch('/api/proxy/force-refresh', {{method: 'POST'}})
                    .then(r => r.json())
                    .then(data => {{
                        alert(data.message || 'Force refresh started!');
                    }})
                    .catch(e => alert('Error: ' + e));
            }}
            
            function testAPI() {{
                fetch('/api/proxy/alive?count=5')
                    .then(r => r.json())
                    .then(data => {{
                        alert('API Response:\\n' + 
                              'Success: ' + data.success + '\\n' +
                              'Available: ' + data.total_available + '\\n' +
                              'Returned: ' + data.returned_count);
                    }})
                    .catch(e => alert('API Error: ' + e));
            }}
            
            function toggleLogs() {{
                const logsContainer = document.getElementById('logs-container');
                logsVisible = !logsVisible;
                logsContainer.style.display = logsVisible ? 'block' : 'none';
                
                if (logsVisible) {{
                    updateLogs();
                }}
            }}
            
            function updateLogs() {{
                if (!logsVisible) return;
                
                fetch('/api/proxy/logs')
                    .then(r => r.json())
                    .then(data => {{
                        const logsEl = document.getElementById('logs');
                        logsEl.innerHTML = data.logs.map(log => 
                            '<div class="log-item log-' + log.type + '">' +
                            '[' + new Date(log.timestamp).toLocaleTimeString() + '] ' +
                            log.message + '</div>'
                        ).reverse().join('');
                        logsEl.scrollTop = logsEl.scrollHeight;
                    }})
                    .catch(e => {{
                        document.getElementById('logs').innerHTML = '<div class="log-item log-error">Error loading logs</div>';
                    }});
            }}
            
            function debugStatus() {{
                fetch('/api/proxy/debug')
                    .then(r => r.json())
                    .then(data => {{
                        alert('üîç DEBUG STATUS:\\n' +
                              'Service Status: ' + JSON.stringify(data.service_status, null, 2) + '\\n\\n' +
                              'Proxy Cache: ' + JSON.stringify(data.proxy_cache, null, 2) + '\\n\\n' +
                              'Current Time: ' + data.current_time);
                    }})
                    .catch(e => alert('Debug Error: ' + e));
            }}
            
            function testFetch() {{
                document.getElementById('service-status').innerHTML = 
                    '<span class="status-indicator status-active"></span>Testing fetch...';
                
                fetch('/api/proxy/test-fetch', {{method: 'POST'}})
                    .then(r => r.json())
                    .then(data => {{
                        if (data.success) {{
                            alert('üì• FETCH TEST SUCCESS:\\n' +
                                  'Source: ' + data.source + '\\n' +
                                  'Status: ' + data.status_code + '\\n' +
                                  'Total Lines: ' + data.total_lines + '\\n' +
                                  'Valid Proxies: ' + data.valid_proxies_found + '\\n' +
                                  'Sample: ' + data.sample_proxies.join(', '));
                        }} else {{
                            alert('‚ùå FETCH TEST FAILED:\\n' + data.error);
                        }}
                    }})
                    .catch(e => alert('Fetch Test Error: ' + e));
            }}
            
            function testValidation() {{
                document.getElementById('service-status').innerHTML = 
                    '<span class="status-indicator status-active"></span>Testing validation...';
                
                fetch('/api/proxy/test-single', {{method: 'POST'}})
                    .then(r => r.json())
                    .then(data => {{
                        if (data.success) {{
                            let results = data.test_results.map(r => 
                                r.proxy + ' = ' + r.status.toUpperCase()
                            ).join('\\n');
                            alert('‚ö° VALIDATION TEST:\\n' + results + '\\n\\nCheck logs for details!');
                        }} else {{
                            alert('‚ùå VALIDATION TEST FAILED:\\n' + data.error);
                        }}
                    }})
                    .catch(e => alert('Validation Test Error: ' + e));
            }}
            
            function quickCheck() {{
                document.getElementById('service-status').innerHTML = 
                    '<span class="status-indicator status-active"></span>Quick checking...';
                
                fetch('/api/proxy/quick-check', {{method: 'POST'}})
                    .then(r => r.json())
                    .then(data => {{
                        if (data.success) {{
                            let resultText = 'üöÄ QUICK CHECK RESULTS:\\n\\n' +
                                'Source: ' + data.source + '\\n' +
                                'Total Lines: ' + data.total_lines + '\\n' +
                                'Parsed Proxies: ' + data.parsed_count + '\\n' +
                                'Tested: ' + data.tested_count + '\\n' +
                                'Alive: ' + data.alive_count + '\\n' +
                                'Conclusion: ' + data.conclusion + '\\n\\n' +
                                'Validation Results:\\n' +
                                data.validation_results.map(r => 
                                    r.proxy + ' = ' + (r.alive ? 'ALIVE (' + r.speed + 's)' : 'DEAD')
                                ).join('\\n') + '\\n\\n' +
                                'Sample Parsed Proxies:\\n' +
                                data.sample_parsed.slice(0, 5).join('\\n');
                                
                            alert(resultText);
                            
                            if (data.conclusion === 'WORKING') {{
                                // If working, trigger force refresh
                                setTimeout(() => {{
                                    if (confirm('üéâ Proxy parsing WORKS! Do you want to trigger full refresh?')) {{
                                        forceRefresh();
                                    }}
                                }}, 1000);
                            }}
                        }} else {{
                            alert('‚ùå QUICK CHECK FAILED:\\n' + data.error + '\\n\\nSource: ' + (data.source || 'unknown'));
                        }}
                    }})
                    .catch(e => alert('Quick Check Error: ' + e));
            }}
            
            // Auto-update
            updateStats();
            setInterval(updateStats, 5000); // Update every 5 seconds
            setInterval(() => {{ if (logsVisible) updateLogs(); }}, 3000);
        </script>
    </body>
    </html>
    """
    return html

@app.route('/api/proxy/alive', methods=['GET'])
def get_alive_proxies():
    """API ch√≠nh - l·∫•y danh s√°ch proxy s·ªëng"""
    try:
        count = int(request.args.get('count', 50))
        
        alive_proxies = proxy_cache.get('http', [])
        
        # Sort by speed (fastest first)
        sorted_proxies = sorted(alive_proxies, key=lambda x: x.get('speed', 999))
        
        # Return requested count
        result_proxies = sorted_proxies[:count]
        
        return jsonify({
            'success': True,
            'total_available': len(alive_proxies),
            'returned_count': len(result_proxies),
            'proxies': result_proxies,
            'last_update': proxy_cache.get('last_update'),
            'timestamp': datetime.now().isoformat(),
            'sources_count': len(PROXY_SOURCE_LINKS)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/stats', methods=['GET'])
def get_proxy_stats():
    """API th·ªëng k√™ proxy"""
    try:
        last_update = proxy_cache.get('last_update')
        cache_age_minutes = 0
        
        if last_update:
            last_update_dt = datetime.fromisoformat(last_update)
            cache_age_minutes = int((datetime.now() - last_update_dt).total_seconds() / 60)
        
        return jsonify({
            'success': True,
            'alive_count': len(proxy_cache.get('http', [])),
            'total_checked': proxy_cache.get('total_checked', 0),
            'last_update': last_update,
            'cache_age_minutes': cache_age_minutes,
            'sources_count': len(PROXY_SOURCE_LINKS),
            'sources': list(PROXY_SOURCE_LINKS.keys()),
            'service_status': 'running',
            'check_interval': '5 minutes',
            # Status tracking
            'is_fetching': service_status.get('is_fetching', False),
            'is_validating': service_status.get('is_validating', False),
            'current_progress': service_status.get('current_progress', 0),
            'total_to_check': service_status.get('total_to_check', 0),
            'sources_checked': service_status.get('sources_checked', 0),
            'total_sources': service_status.get('total_sources', len(PROXY_SOURCE_LINKS))
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/force-refresh', methods=['POST'])
def force_refresh():
    """API bu·ªôc refresh proxy ngay l·∫≠p t·ª©c"""
    try:
        if service_status.get('is_fetching') or service_status.get('is_validating'):
            return jsonify({
                'success': False,
                'message': 'Service ƒëang b·∫≠n, vui l√≤ng ƒë·ª£i...'
            })
        
        # Start force refresh in background
        def force_refresh_task():
            try:
                add_log("üöÄ FORCE REFRESH ƒë∆∞·ª£c k√≠ch ho·∫°t b·ªüi user!", "info")
                
                # Fetch new proxies from sources
                raw_proxies = fetch_proxies_from_sources()
                
                if raw_proxies:
                    # Process more proxies for better coverage
                    limited_proxies = raw_proxies[:1000]
                    add_log(f"üéØ Force refresh: validate {len(limited_proxies)} proxy", "info")
                    
                    # Validate them
                    alive_proxies = validate_proxy_batch(limited_proxies)
                    
                    # Update cache
                    proxy_cache["http"] = alive_proxies
                    proxy_cache["last_update"] = datetime.now().isoformat()
                    proxy_cache["total_checked"] = len(limited_proxies)
                    proxy_cache["alive_count"] = len(alive_proxies)
                    
                    add_log(f"üéâ Force refresh ho√†n th√†nh: {len(alive_proxies)} proxy s·ªëng!", "success")
                else:
                    add_log("‚ùå Force refresh: Kh√¥ng fetch ƒë∆∞·ª£c proxy", "error")
                    
            except Exception as e:
                add_log(f"‚ùå L·ªói force refresh: {str(e)}", "error")
        
        # Start in background thread
        refresh_thread = threading.Thread(target=force_refresh_task, daemon=True)
        refresh_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'Force refresh ƒë√£ b·∫Øt ƒë·∫ßu! Ki·ªÉm tra logs ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô.'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/logs', methods=['GET'])
def get_logs():
    """API l·∫•y logs c·ªßa service"""
    try:
        logs = service_status.get('logs', [])
        
        return jsonify({
            'success': True,
            'logs': logs[-50:],  # Return last 50 logs
            'total_logs': len(logs)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/debug', methods=['GET'])
def debug_status():
    """API debug - ki·ªÉm tra t·∫•t c·∫£ th√¥ng tin service"""
    try:
        return jsonify({
            'success': True,
            'service_status': service_status,
            'proxy_cache': {
                'http_count': len(proxy_cache.get('http', [])),
                'last_update': proxy_cache.get('last_update'),
                'total_checked': proxy_cache.get('total_checked', 0),
                'alive_count': proxy_cache.get('alive_count', 0)
            },
            'current_time': datetime.now().isoformat(),
            'sources': list(PROXY_SOURCE_LINKS.keys())
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/test-single', methods=['POST'])
def test_single_proxy():
    """API test 1 proxy ƒë·ªÉ debug validation logic"""
    try:
        # Test v·ªõi proxy m·∫´u
        test_proxies = [
            "8.8.8.8:80",  # Google DNS (s·∫Ω fail v√¨ kh√¥ng ph·∫£i proxy)
            "proxy.example.com:8080",  # Fake proxy
            "1.1.1.1:80"   # Cloudflare DNS (s·∫Ω fail)
        ]
        
        results = []
        for proxy in test_proxies:
            add_log(f"üß™ Test proxy: {proxy}", "info")
            result = check_single_proxy(proxy, timeout=5)  # Shorter timeout for test
            results.append({
                'proxy': proxy,
                'result': result,
                'status': 'alive' if result else 'dead'
            })
            add_log(f"üß™ Result: {proxy} = {'ALIVE' if result else 'DEAD'}", "success" if result else "error")
        
        return jsonify({
            'success': True,
            'test_results': results,
            'message': f'Tested {len(test_proxies)} proxies'
        })
        
    except Exception as e:
        add_log(f"‚ùå Error in test-single: {str(e)}", "error")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/test-fetch', methods=['POST'])
def test_fetch_sources():
    """API test fetch t·ª´ 1 source ƒë·ªÉ debug"""
    try:
        # Test v·ªõi 1 source ƒë·∫ßu ti√™n
        source_name = list(PROXY_SOURCE_LINKS.keys())[0]
        source_urls = PROXY_SOURCE_LINKS[source_name]
        
        add_log(f"üß™ Test fetch t·ª´ {source_name}...", "info")
        
        for protocol, source_url in source_urls.items():
            try:
                response = requests.get(source_url, timeout=10)
                
                if response.status_code == 200:
                    content = response.text
                    lines = content.strip().split('\n')
                    
                    # Use NEW relaxed validation logic
                    valid_proxies = []
                    parse_errors = []
                    
                    for i, line in enumerate(lines[:100]):  # Check more lines for better parsing
                        line = line.strip()
                        if not line or line.startswith('#'):
                            continue
                            
                        if ':' in line:
                            try:
                                # Use same logic as in fetch_proxies_from_sources
                                proxy_candidate = line.strip()
                                
                                # Remove common prefixes
                                for prefix in ['http://', 'https://', 'socks4://', 'socks5://']:
                                    if proxy_candidate.startswith(prefix):
                                        proxy_candidate = proxy_candidate[len(prefix):]
                                
                                # Parse proxy format
                                if '@' in proxy_candidate:
                                    auth_part, host_port = proxy_candidate.split('@', 1)
                                    if ':' in host_port:
                                        host, port = host_port.split(':', 1)
                                    else:
                                        parse_errors.append(f"Line {i}: No port in auth format")
                                        continue
                                else:
                                    parts = proxy_candidate.split(':')
                                    if len(parts) >= 2:
                                        host, port = parts[0], parts[1]
                                    else:
                                        parse_errors.append(f"Line {i}: Not enough parts")
                                        continue
                                
                                # Relaxed validation
                                if (host and port and 
                                    port.isdigit() and 
                                    1 <= int(port) <= 65535 and
                                    '.' in host and 
                                    len(host) > 7):
                                    
                                    clean_proxy = f"{host.strip()}:{port.strip()}"
                                    valid_proxies.append(clean_proxy)
                                else:
                                    parse_errors.append(f"Line {i}: Validation failed - host='{host}', port='{port}'")
                                    
                            except Exception as e:
                                parse_errors.append(f"Line {i}: Exception - {str(e)}")
                                continue
                    
                    add_log(f"‚úÖ {source_name} ({protocol}): T√¨m th·∫•y {len(valid_proxies)} proxy valid t·ª´ {len(lines)} d√≤ng (NEW logic)", "success")
                    
                    return jsonify({
                        'success': True,
                        'source': source_name,
                        'protocol': protocol,
                        'url': source_url,
                        'status_code': response.status_code,
                        'total_lines': len(lines),
                        'valid_proxies_found': len(valid_proxies),
                        'sample_proxies': valid_proxies[:5],
                        'raw_sample': lines[:10],
                        'parse_errors': parse_errors[:5],  # First 5 errors for debug
                        'validation_method': 'NEW_RELAXED'
                    })
                else:
                    add_log(f"‚ùå {source_name} ({protocol}): HTTP {response.status_code}", "error")
                    return jsonify({
                        'success': False,
                        'source': source_name,
                        'protocol': protocol,
                        'status_code': response.status_code,
                        'error': f'HTTP {response.status_code}'
                    })
            except Exception as e:
                add_log(f"‚ùå Error test-fetch for {source_name} ({protocol}): {str(e)}", "error")
                return jsonify({
                    'success': False,
                    'source': source_name,
                    'protocol': protocol,
                    'error': str(e)
                }), 500
        
        return jsonify({
            'success': False,
            'message': f'Kh√¥ng th·ªÉ test fetch t·ª´ {source_name} do l·ªói kh√¥ng x√°c ƒë·ªãnh.'
        }), 500
        
    except Exception as e:
        add_log(f"‚ùå Error test-fetch: {str(e)}", "error")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/proxy/quick-check', methods=['POST'])
def quick_check():
    """API quick check - fetch v√† validate 20 proxy nhanh"""
    try:
        add_log("üöÄ QUICK CHECK b·∫Øt ƒë·∫ßu...", "info")
        
        # Fetch t·ª´ source ƒë·∫ßu ti√™n
        source_name = list(PROXY_SOURCE_LINKS.keys())[0]
        source_urls = PROXY_SOURCE_LINKS[source_name]
        
        add_log(f"üîç Fetching from {source_name}...", "info")
        
        for protocol, source_url in source_urls.items():
            try:
                response = requests.get(source_url, timeout=15)
                
                if response.status_code != 200:
                    add_log(f"‚ùå {source_name} ({protocol}): HTTP {response.status_code}", "error")
                    continue
                
                # Parse v·ªõi TOOL LOGIC
                content = response.text
                lines = content.strip().split('\n')
                parsed_proxies = []
                parse_stats = {'total_lines': 0, 'valid_format': 0, 'auto_detected': {}}
                
                add_log(f"üìù Parsing {len(lines)} lines from {source_name} ({protocol})...", "info")
                
                for line in lines:  # Process ALL lines from source
                    line = line.strip()
                    parse_stats['total_lines'] += 1
                    
                    if not line or line.startswith('#'):
                        continue
                        
                    if ':' in line:
                        # Clean prefixes
                        proxy_candidate = line.strip()
                        for prefix in ['http://', 'https://', 'socks4://', 'socks5://']:
                            if proxy_candidate.startswith(prefix):
                                proxy_candidate = proxy_candidate[len(prefix):]
                        
                        # Use tool's parse logic
                        parsed = parse_proxy_line(proxy_candidate, "auto")
                        if parsed:
                            clean_proxy = f"{parsed['host']}:{parsed['port']}"
                            parsed_proxies.append(clean_proxy)
                            parse_stats['valid_format'] += 1
                            
                            # Track auto-detected protocols
                            protocol = parsed['type']
                            parse_stats['auto_detected'][protocol] = parse_stats['auto_detected'].get(protocol, 0) + 1
                            
                            if len(parsed_proxies) >= 1000:  # Allow up to 1000 proxies per source
                                break
                
                protocol_summary = ", ".join([f"{k}: {v}" for k, v in parse_stats['auto_detected'].items()])
                add_log(f"üéØ Parsed {len(parsed_proxies)} proxy t·ª´ {source_name} ({protocol}) | Protocols: {protocol_summary}", "success")
                
                if not parsed_proxies:
                    add_log(f"‚ùå {source_name} ({protocol}): Kh√¥ng parse ƒë∆∞·ª£c proxy n√†o", "error")
                    continue
                
                # Test validate 5 proxy ƒë·∫ßu ti√™n gi·ªëng tool
                test_proxies = parsed_proxies[:5]
                validated_results = []
                
                add_log(f"üß™ Testing {len(test_proxies)} proxies from {source_name} ({protocol})...", "info")
                
                for i, proxy in enumerate(test_proxies):
                    add_log(f"üîç Testing {i+1}/{len(test_proxies)}: {proxy}", "info")
                    
                    # Check if this is from mixed source -> use special validation
                    if source_name == "Mixed Sources":
                        result = check_mixed_proxy_all_protocols(proxy, timeout=8)
                        if result:
                            validated_results.append({
                                'proxy': proxy,
                                'alive': True,
                                'speed': result['speed'],
                                'latency': result['latency'],
                                'ip': result['ip'],
                                'type': result['type'],
                                'method': 'mixed_protocol_test'
                            })
                            add_log(f"‚úÖ MIXED ALIVE: {proxy} ‚Üí {result['ip']} | {result['latency']}ms | Protocol: {result['type']}", "success")
                        else:
                            validated_results.append({
                                'proxy': proxy,
                                'alive': False,
                                'speed': None,
                                'error': 'Failed all protocols',
                                'method': 'mixed_protocol_test'
                            })
                            add_log(f"üíÄ MIXED DEAD: {proxy} ‚Üí Failed all protocols", "error")
                    else:
                        # Standard validation for categorized sources
                        result = check_single_proxy(proxy, timeout=8)
                        if result and result['status'] == 'alive':
                            validated_results.append({
                                'proxy': proxy,
                                'alive': True,
                                'speed': result['speed'],
                                'latency': result['latency'],
                                'ip': result['ip'],
                                'type': result['type'],
                                'method': 'categorized_test'
                            })
                            add_log(f"‚úÖ ALIVE: {proxy} ‚Üí {result['ip']} | {result['latency']}ms", "success")
                        else:
                            error_msg = result.get('error', 'Unknown error') if result else 'Parse failed'
                            validated_results.append({
                                'proxy': proxy,
                                'alive': False,
                                'speed': None,
                                'error': error_msg,
                                'method': 'categorized_test'
                            })
                            add_log(f"üíÄ DEAD: {proxy} ‚Üí {error_msg}", "error")
                
                alive_count = sum(1 for r in validated_results if r['alive'])
                success_rate = (alive_count/len(test_proxies)*100) if test_proxies else 0
                add_log(f"üìä Quick check complete for {source_name} ({protocol}): {alive_count}/{len(test_proxies)} alive ({success_rate:.1f}%)", "info")
                
                # If any source is working, return success
                if alive_count > 0:
                    return jsonify({
                        'success': True,
                        'source': source_name,
                        'protocol': protocol,
                        'total_lines': len(lines),
                        'parsed_count': len(parsed_proxies),
                        'tested_count': len(test_proxies),
                        'alive_count': alive_count,
                        'sample_parsed': parsed_proxies[:10],
                        'validation_results': validated_results,
                        'parse_stats': parse_stats,
                        'parse_ratio': f"{len(parsed_proxies)}/{len(lines)} ({len(parsed_proxies)/len(lines)*100:.1f}%)",
                        'alive_ratio': f"{alive_count}/{len(test_proxies)} ({success_rate:.1f}%)",
                        'conclusion': 'WORKING'
                    })
            
            except Exception as e:
                add_log(f"‚ùå Quick check error for {source_name} ({protocol}): {str(e)}", "error")
                continue
        
        return jsonify({
            'success': False,
            'error': 'Kh√¥ng t√¨m th·∫•y proxy s·ªëng t·ª´ b·∫•t k·ª≥ ngu·ªìn n√†o trong danh s√°ch nhanh ki·ªÉm tra.',
            'sources_checked': list(PROXY_SOURCE_LINKS.keys()),
            'conclusion': 'NEED_INVESTIGATION'
        })
        
    except Exception as e:
        add_log(f"‚ùå Quick check error: {str(e)}", "error")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    # Initialize logging
    add_log("üöÄ Kh·ªüi ƒë·ªông Proxy Validation Service...", "info")
    
    # Start background refresh thread
    add_log("üîß Kh·ªüi ƒë·ªông background refresh thread...", "info")
    refresh_thread = threading.Thread(target=background_proxy_refresh, daemon=True)
    refresh_thread.start()
    
    # INITIAL PROXY LOAD NHANH - C√≥ k·∫øt qu·∫£ trong 30-60 gi√¢y
    add_log("‚ö° B·∫ÆT ƒê·∫¶U INITIAL LOAD NHANH...", "info")
    try:
        initial_proxies = fetch_proxies_from_sources()
        if initial_proxies:
            # STRATEGY: Load h·ª£p l√Ω ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c
            limited_initial = initial_proxies[:400]  # Pool 400 proxy cho initial load
            add_log(f"üöÄ INITIAL BALANCED LOAD: {len(limited_initial)} proxy t·ª´ {len(initial_proxies)} t·ªïng | Target: 40 alive", "info")
            
            # Use c√¢n b·∫±ng validation cho initial load
            initial_alive = validate_proxy_batch_fast(
                limited_initial,
                max_workers=50,      # Workers c√¢n b·∫±ng
                target_alive=40,     # Target 40 proxy ƒë·ªÉ b·∫Øt ƒë·∫ßu t·ªët
                chunk_size=40,       # Chunks h·ª£p l√Ω
                timeout=8           # Timeout chu·∫©n 8s
            )
            
            proxy_cache["http"] = initial_alive
            proxy_cache["last_update"] = datetime.now().isoformat()
            proxy_cache["total_checked"] = len(limited_initial)
            proxy_cache["alive_count"] = len(initial_alive)
            
            if len(initial_alive) > 0:
                add_log(f"üéâ INITIAL LOAD TH√ÄNH C√îNG: {len(initial_alive)} proxy s·ªëng! Service s·∫µn s√†ng.", "success")
            else:
                add_log("‚ö†Ô∏è Initial load: Ch∆∞a c√≥ proxy s·ªëng, background s·∫Ω ti·∫øp t·ª•c t√¨m...", "info")
        else:
            add_log("‚ùå Initial load: Kh√¥ng fetch ƒë∆∞·ª£c proxy t·ª´ sources", "error")
    except Exception as e:
        add_log(f"‚ùå L·ªói initial load: {str(e)}", "error")
        # Set empty cache ƒë·ªÉ service v·∫´n ch·∫°y ƒë∆∞·ª£c
        proxy_cache["http"] = []
        proxy_cache["last_update"] = datetime.now().isoformat()
        proxy_cache["total_checked"] = 0
        proxy_cache["alive_count"] = 0
    
    # Start Flask app
    port = int(os.environ.get('PORT', 5000))
    add_log(f"üåê Kh·ªüi ƒë·ªông Flask app tr√™n port {port}", "info")
    print(f"üåê Starting Flask app on port {port}")
    app.run(host='0.0.0.0', port=port, debug=False) 